# 🤖 Tutorial MLOps: Model Training & Experimentation

## 📋 Tabla de Responsabilidades

| Entregable                     | Responsable         |
| ------------------------------ | ------------------- |
| 📓 Experimentación con modelos | Científico de datos |
| 🔧 Script de entrenamiento     | Ingeniero de MLOps  |
| 📊 Tracking con MLflow         | Ingeniero de MLOps  |
| 🤖 Modelo serializado          | Ingeniero de MLOps  |
| ⚙️ Configuración de modelos    | Ingeniero de MLOps  |
| 🔄 Pipeline automatizado       | Ingeniero de MLOps  |

---

## 🎯 Paso 3: De Experimentación a Pipeline de Entrenamiento

### 📚 **¿Qué recibe el MLOps Engineer?**

El científico de datos entrega un notebook `03_experimentation.ipynb` con experimentación exploratoria:

```python
# 📓 Código del Data Scientist en Jupyter
import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# Experimentación con múltiples modelos
models = {
    'LinearRegression': LinearRegression(),
    'RandomForest': RandomForestRegressor(),
    'GradientBoosting': GradientBoostingRegressor(),
    'HistGradientBoosting': HistGradientBoostingRegressor()
}

# GridSearch manual para cada modelo
for name, model in models.items():
    with mlflow.start_run(run_name=name, nested=True):
        clf = GridSearchCV(model, grid, cv=3, scoring='r2')
        clf.fit(X_train, y_train)
        # Logging manual de métricas...
```

### ⚡ **Transformación a Script de Producción**

El MLOps Engineer convierte esto en `src/models/train_model.py`:

```python
# 🔧 Script de Producción del MLOps Engineer
import argparse
import pandas as pd
import numpy as np
import joblib
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor
from sklearn.linear_model import LinearRegression
import yaml
import logging
from mlflow.tracking import MlflowClient

# Configuración de logging profesional
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def parse_args():
    """Argumentos de línea de comandos configurables."""
    parser = argparse.ArgumentParser(description="Train and register final model from config.")
    parser.add_argument("--config", type=str, required=True, help="Path to model_config.yaml")
    parser.add_argument("--data", type=str, required=True, help="Path to processed CSV dataset")
    parser.add_argument("--models-dir", type=str, required=True, help="Directory to save trained model")
    parser.add_argument("--mlflow-tracking-uri", type=str, default=None, help="MLflow tracking URI")
    return parser.parse_args()

def get_model_instance(name, params):
    """Factory para instanciar modelos desde configuración."""
    model_map = {
        'LinearRegression': LinearRegression,
        'RandomForest': RandomForestRegressor,
        'GradientBoosting': GradientBoostingRegressor,
        'HistGradientBoosting': HistGradientBoostingRegressor,
    }
    if name not in model_map:
        raise ValueError(f"Unsupported model: {name}")
    return model_map[name](**params)

def load_and_split_data(data_path, config):
    """Carga y divide datos usando configuración."""
    logger.info(f"Loading data from {data_path}")
    data = pd.read_csv(data_path)

    # Usar características seleccionadas de la experimentación
    selected_features = config['model']['feature_sets']['rfe']
    logger.info(f"Using {len(selected_features)} selected features")

    X = data[selected_features]
    y = data[config['model']['target_variable']]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    logger.info(f"Data split: Train {X_train.shape}, Test {X_test.shape}")
    return X_train, X_test, y_train, y_test

def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):
    """Entrena y evalúa el modelo."""
    logger.info("Training model...")
    model.fit(X_train, y_train)

    # Predicciones y métricas
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))

    metrics = {
        'mae': mae,
        'r2': r2,
        'rmse': rmse
    }

    logger.info(f"Model performance - R²: {r2:.4f}, MAE: {mae:.2f}, RMSE: {rmse:.2f}")
    return model, metrics

def save_model_artifacts(model, config, metrics, models_dir):
    """Guarda modelo y artefactos."""
    import os
    os.makedirs(models_dir, exist_ok=True)

    # Guardar modelo entrenado
    model_path = os.path.join(models_dir, 'trained/house_price_model.pkl')
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(model, model_path)

    # Actualizar configuración con métricas finales
    config['model']['final_metrics'] = {
        'mae': float(metrics['mae']),
        'r2': float(metrics['r2']),
        'rmse': float(metrics['rmse'])
    }

    # Guardar configuración actualizada
    config_path = os.path.join(models_dir, 'trained/house_price_model.yaml')
    with open(config_path, 'w') as f:
        yaml.dump(config, f)

    logger.info(f"✅ Model saved to {model_path}")
    logger.info(f"✅ Config saved to {config_path}")

    return model_path, config_path

def register_model_in_mlflow(model, config, metrics, mlflow_tracking_uri):
    """Registra modelo en MLflow con metadatos completos."""
    if not mlflow_tracking_uri:
        logger.info("No MLflow tracking URI provided, skipping MLflow logging")
        return None

    mlflow.set_tracking_uri(mlflow_tracking_uri)
    mlflow.set_experiment("House Price Prediction - Production")

    model_name = config['model']['name']

    with mlflow.start_run(run_name="production_training"):
        # Log parámetros del modelo
        mlflow.log_params(config['model']['parameters'])

        # Log métricas de rendimiento
        mlflow.log_metrics(metrics)

        # Log información adicional
        mlflow.log_param("selected_features_count",
                        config['model']['feature_sets']['selected_features_count'])
        mlflow.log_param("feature_selection_method",
                        config['model']['feature_sets']['rfe_method'])

        # Registrar modelo
        mlflow.sklearn.log_model(
            sk_model=model,
            artifact_path="model",
            registered_model_name=model_name,
            signature=mlflow.models.infer_signature(None, None)
        )

        # Transicionar a producción si las métricas son buenas
        if metrics['r2'] > 0.8:  # Threshold configurable
            client = MlflowClient()
            model_version = client.get_latest_versions(model_name, stages=["None"])[0]
            client.transition_model_version_stage(
                name=model_name,
                version=model_version.version,
                stage="Production"
            )
            logger.info(f"✅ Model promoted to Production stage in MLflow")

        run_id = mlflow.active_run().info.run_id
        logger.info(f"✅ Model logged to MLflow with run_id: {run_id}")
        return run_id

def main():
    """Pipeline principal de entrenamiento."""
    args = parse_args()

    # Cargar configuración del modelo
    logger.info(f"Loading config from {args.config}")
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)

    # Cargar y preparar datos
    X_train, X_test, y_train, y_test = load_and_split_data(args.data, config)

    # Instanciar modelo desde configuración
    model_name = config['model']['best_model']
    model_params = config['model']['parameters']
    model = get_model_instance(model_name, model_params)
    logger.info(f"Created {model_name} model with parameters: {model_params}")

    # Entrenar y evaluar
    trained_model, metrics = train_and_evaluate_model(
        model, X_train, y_train, X_test, y_test
    )

    # Guardar artefactos localmente
    model_path, config_path = save_model_artifacts(
        trained_model, config, metrics, args.models_dir
    )

    # Registrar en MLflow
    run_id = register_model_in_mlflow(
        trained_model, config, metrics, args.mlflow_tracking_uri
    )

    logger.info("🚀 Training pipeline completed successfully!")

    return {
        'model_path': model_path,
        'config_path': config_path,
        'metrics': metrics,
        'mlflow_run_id': run_id
    }

if __name__ == "__main__":
    main()
```

## 🔑 **Diferencias Clave: Notebook vs Script de Entrenamiento**

### 📓 **Código del Data Scientist (Notebook)**

- ✅ Experimentación interactiva con múltiples modelos
- ✅ GridSearch manual y comparación visual
- ✅ Análisis exploratorio de características
- ❌ Código no reutilizable entre experimentos
- ❌ Configuración hardcodeada
- ❌ Sin gestión automática de artefactos
- ❌ Difícil de integrar en CI/CD

### 🔧 **Código del MLOps Engineer (Script)**

- ✅ **Configurable**: Todo parametrizado via YAML
- ✅ **Reproducible**: Mismo resultado en cualquier ambiente
- ✅ **Traceable**: Logging completo con MLflow
- ✅ **Automatizable**: CLI para integración CI/CD
- ✅ **Versionado**: Gestión automática de modelos
- ✅ **Auditoria**: Métricas y metadatos registrados

## 📋 **Flujo de Configuración YAML**

### **`configs/model_config.yaml`** (Generado por experimentación)

```yaml
model:
  name: house_price_model
  best_model: RandomForest # Resultado de experimentación
  parameters:
    n_estimators: 200
    max_depth: 15
    min_samples_split: 5
    min_samples_leaf: 2
    random_state: 42
  r2_score: 0.8756
  mae: 15234.67
  target_variable: price
  feature_sets:
    rfe:
      - sqft
      - house_age
      - bedrooms
      - bathrooms
      - price_per_sqft
      - bed_bath_ratio
      - location_Suburb
      - condition_Good
      - year_built
      - condition_Excellent
    rfe_method: RandomForestRegressor
    total_features: 25
    selected_features_count: 10
```

## 🚀 **Ejecutar el Pipeline de Entrenamiento**

### 1. **Asegurar que MLflow esté ejecutándose:**

```bash
cd deployment/mlflow
docker compose up -d
```

### 2. **Ejecutar entrenamiento de producción:**

```bash
python src/models/train_model.py \
  --config configs/model_config.yaml \
  --data data/processed/featured_house_data.csv \
  --models-dir models \
  --mlflow-tracking-uri http://localhost:5555
```

### 3. **Output esperado:**

```
2025-07-24 14:30:15 - INFO - Loading config from configs/model_config.yaml
2025-07-24 14:30:15 - INFO - Loading data from data/processed/featured_house_data.csv
2025-07-24 14:30:15 - INFO - Using 10 selected features
2025-07-24 14:30:15 - INFO - Data split: Train (800, 10), Test (200, 10)
2025-07-24 14:30:15 - INFO - Created RandomForest model with parameters: {'n_estimators': 200, 'max_depth': 15, ...}
2025-07-24 14:30:16 - INFO - Training model...
2025-07-24 14:30:18 - INFO - Model performance - R²: 0.8756, MAE: 15234.67, RMSE: 19876.43
2025-07-24 14:30:18 - INFO - ✅ Model saved to models/trained/house_price_model.pkl
2025-07-24 14:30:19 - INFO - ✅ Model promoted to Production stage in MLflow
2025-07-24 14:30:19 - INFO - ✅ Model logged to MLflow with run_id: a1b2c3d4e5f6
2025-07-24 14:30:19 - INFO - 🚀 Training pipeline completed successfully!
```

## 📦 **Archivos Generados**

### 1. **`models/trained/house_price_model.pkl`**

```python
# Modelo entrenado serializado con joblib
import joblib
model = joblib.load('models/trained/house_price_model.pkl')
predictions = model.predict(X_new)
```

### 2. **MLflow Model Registry**

- 🔄 **Experiment**: "House Price Prediction - Production"
- 🏷️ **Model Name**: "house_price_model"
- 🎯 **Stage**: "Production" (si R² > 0.8)
- 📊 **Metrics**: MAE, R², RMSE registradas
- 🔧 **Parameters**: Hyperparámetros del modelo
- 📋 **Artifacts**: Modelo serializado

## 🔄 **Integración con el Pipeline MLOps**

### **1. Data Processing → Feature Engineering → Model Training**

```bash
# Pipeline completo automatizado
python src/data/run_processing.py \
  --input data/raw/house_data.csv \
  --output data/processed/cleaned_house_data.csv

python src/features/engineer.py \
  --input data/processed/cleaned_house_data.csv \
  --output data/processed/featured_house_data.csv \
  --preprocessor models/trained/preprocessor.pkl

python src/models/train_model.py \
  --config configs/model_config.yaml \
  --data data/processed/featured_house_data.csv \
  --models-dir models \
  --mlflow-tracking-uri http://localhost:5555
```

### **2. Para usar el modelo entrenado en la API:**

```python
# En src/api/inference.py
import joblib

model = joblib.load('models/trained/house_price_model.pkl')
preprocessor = joblib.load('models/trained/preprocessor.pkl')

def predict(raw_features):
    # Transformar características
    features_transformed = preprocessor.transform([raw_features])
    # Hacer predicción
    prediction = model.predict(features_transformed)
    return prediction[0]
```

## ✅ **Beneficios del Script de Producción**

1. **🎯 Configuración Declarativa**: Todo en YAML, fácil de modificar
2. **🔄 Reproducibilidad**: Mismos resultados en cualquier ambiente
3. **📊 Trazabilidad**: MLflow registra todo automáticamente
4. **⚡ Automatización**: CLI lista para CI/CD
5. **🛡️ Validación**: Métricas y promoción automática
6. **🔧 Mantenimiento**: Logging y manejo de errores robusto

---

## 🔮 **Próximos Pasos**

En los siguientes tutoriales del pipeline MLOps cubriremos:

- **Tutorial 4**: API REST con FastAPI (✅ Ya existe)
- **Tutorial 5**: App de demostración con Streamlit (✅ Ya existe)
- **Tutorial 6**: CI/CD Pipeline con GitHub Actions
- **Tutorial 7**: Deployment en Kubernetes

**¡El Model Training automatizado es el corazón del pipeline MLOps!** 🚀
