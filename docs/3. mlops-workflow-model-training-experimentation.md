# ğŸ¤– Tutorial MLOps: Model Training & Experimentation

## ğŸ“‹ Tabla de Responsabilidades

| Entregable                     | Responsable         |
| ------------------------------ | ------------------- |
| ğŸ““ ExperimentaciÃ³n con modelos | CientÃ­fico de datos |
| ğŸ”§ Script de entrenamiento     | Ingeniero de MLOps  |
| ğŸ“Š Tracking con MLflow         | Ingeniero de MLOps  |
| ğŸ¤– Modelo serializado          | Ingeniero de MLOps  |
| âš™ï¸ ConfiguraciÃ³n de modelos    | Ingeniero de MLOps  |
| ğŸ”„ Pipeline automatizado       | Ingeniero de MLOps  |

---

## ğŸ¯ Paso 3: De ExperimentaciÃ³n a Pipeline de Entrenamiento

### ğŸ“š **Â¿QuÃ© recibe el MLOps Engineer?**

El cientÃ­fico de datos entrega un notebook `03_experimentation.ipynb` con experimentaciÃ³n exploratoria:

```python
# ğŸ““ CÃ³digo del Data Scientist en Jupyter
import pandas as pd
import numpy as np
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor

# ExperimentaciÃ³n con mÃºltiples modelos
models = {
    'LinearRegression': LinearRegression(),
    'RandomForest': RandomForestRegressor(),
    'GradientBoosting': GradientBoostingRegressor(),
    'HistGradientBoosting': HistGradientBoostingRegressor()
}

# GridSearch manual para cada modelo
for name, model in models.items():
    with mlflow.start_run(run_name=name, nested=True):
        clf = GridSearchCV(model, grid, cv=3, scoring='r2')
        clf.fit(X_train, y_train)
        # Logging manual de mÃ©tricas...
```

### âš¡ **TransformaciÃ³n a Script de ProducciÃ³n**

El MLOps Engineer convierte esto en `src/models/train_model.py`:

```python
# ğŸ”§ Script de ProducciÃ³n del MLOps Engineer
import argparse
import pandas as pd
import numpy as np
import joblib
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, HistGradientBoostingRegressor
from sklearn.linear_model import LinearRegression
import yaml
import logging
from mlflow.tracking import MlflowClient

# ConfiguraciÃ³n de logging profesional
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def parse_args():
    """Argumentos de lÃ­nea de comandos configurables."""
    parser = argparse.ArgumentParser(description="Train and register final model from config.")
    parser.add_argument("--config", type=str, required=True, help="Path to model_config.yaml")
    parser.add_argument("--data", type=str, required=True, help="Path to processed CSV dataset")
    parser.add_argument("--models-dir", type=str, required=True, help="Directory to save trained model")
    parser.add_argument("--mlflow-tracking-uri", type=str, default=None, help="MLflow tracking URI")
    return parser.parse_args()

def get_model_instance(name, params):
    """Factory para instanciar modelos desde configuraciÃ³n."""
    model_map = {
        'LinearRegression': LinearRegression,
        'RandomForest': RandomForestRegressor,
        'GradientBoosting': GradientBoostingRegressor,
        'HistGradientBoosting': HistGradientBoostingRegressor,
    }
    if name not in model_map:
        raise ValueError(f"Unsupported model: {name}")
    return model_map[name](**params)

def load_and_split_data(data_path, config):
    """Carga y divide datos usando configuraciÃ³n."""
    logger.info(f"Loading data from {data_path}")
    data = pd.read_csv(data_path)

    # Usar caracterÃ­sticas seleccionadas de la experimentaciÃ³n
    selected_features = config['model']['feature_sets']['rfe']
    logger.info(f"Using {len(selected_features)} selected features")

    X = data[selected_features]
    y = data[config['model']['target_variable']]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )

    logger.info(f"Data split: Train {X_train.shape}, Test {X_test.shape}")
    return X_train, X_test, y_train, y_test

def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):
    """Entrena y evalÃºa el modelo."""
    logger.info("Training model...")
    model.fit(X_train, y_train)

    # Predicciones y mÃ©tricas
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    rmse = np.sqrt(np.mean((y_test - y_pred) ** 2))

    metrics = {
        'mae': mae,
        'r2': r2,
        'rmse': rmse
    }

    logger.info(f"Model performance - RÂ²: {r2:.4f}, MAE: {mae:.2f}, RMSE: {rmse:.2f}")
    return model, metrics

def save_model_artifacts(model, config, metrics, models_dir):
    """Guarda modelo y artefactos."""
    import os
    os.makedirs(models_dir, exist_ok=True)

    # Guardar modelo entrenado
    model_path = os.path.join(models_dir, 'trained/house_price_model.pkl')
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    joblib.dump(model, model_path)

    # Actualizar configuraciÃ³n con mÃ©tricas finales
    config['model']['final_metrics'] = {
        'mae': float(metrics['mae']),
        'r2': float(metrics['r2']),
        'rmse': float(metrics['rmse'])
    }

    # Guardar configuraciÃ³n actualizada
    config_path = os.path.join(models_dir, 'trained/house_price_model.yaml')
    with open(config_path, 'w') as f:
        yaml.dump(config, f)

    logger.info(f"âœ… Model saved to {model_path}")
    logger.info(f"âœ… Config saved to {config_path}")

    return model_path, config_path

def register_model_in_mlflow(model, config, metrics, mlflow_tracking_uri):
    """Registra modelo en MLflow con metadatos completos."""
    if not mlflow_tracking_uri:
        logger.info("No MLflow tracking URI provided, skipping MLflow logging")
        return None

    mlflow.set_tracking_uri(mlflow_tracking_uri)
    mlflow.set_experiment("House Price Prediction - Production")

    model_name = config['model']['name']

    with mlflow.start_run(run_name="production_training"):
        # Log parÃ¡metros del modelo
        mlflow.log_params(config['model']['parameters'])

        # Log mÃ©tricas de rendimiento
        mlflow.log_metrics(metrics)

        # Log informaciÃ³n adicional
        mlflow.log_param("selected_features_count",
                        config['model']['feature_sets']['selected_features_count'])
        mlflow.log_param("feature_selection_method",
                        config['model']['feature_sets']['rfe_method'])

        # Registrar modelo
        mlflow.sklearn.log_model(
            sk_model=model,
            artifact_path="model",
            registered_model_name=model_name,
            signature=mlflow.models.infer_signature(None, None)
        )

        # Transicionar a producciÃ³n si las mÃ©tricas son buenas
        if metrics['r2'] > 0.8:  # Threshold configurable
            client = MlflowClient()
            model_version = client.get_latest_versions(model_name, stages=["None"])[0]
            client.transition_model_version_stage(
                name=model_name,
                version=model_version.version,
                stage="Production"
            )
            logger.info(f"âœ… Model promoted to Production stage in MLflow")

        run_id = mlflow.active_run().info.run_id
        logger.info(f"âœ… Model logged to MLflow with run_id: {run_id}")
        return run_id

def main():
    """Pipeline principal de entrenamiento."""
    args = parse_args()

    # Cargar configuraciÃ³n del modelo
    logger.info(f"Loading config from {args.config}")
    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)

    # Cargar y preparar datos
    X_train, X_test, y_train, y_test = load_and_split_data(args.data, config)

    # Instanciar modelo desde configuraciÃ³n
    model_name = config['model']['best_model']
    model_params = config['model']['parameters']
    model = get_model_instance(model_name, model_params)
    logger.info(f"Created {model_name} model with parameters: {model_params}")

    # Entrenar y evaluar
    trained_model, metrics = train_and_evaluate_model(
        model, X_train, y_train, X_test, y_test
    )

    # Guardar artefactos localmente
    model_path, config_path = save_model_artifacts(
        trained_model, config, metrics, args.models_dir
    )

    # Registrar en MLflow
    run_id = register_model_in_mlflow(
        trained_model, config, metrics, args.mlflow_tracking_uri
    )

    logger.info("ğŸš€ Training pipeline completed successfully!")

    return {
        'model_path': model_path,
        'config_path': config_path,
        'metrics': metrics,
        'mlflow_run_id': run_id
    }

if __name__ == "__main__":
    main()
```

## ğŸ”‘ **Diferencias Clave: Notebook vs Script de Entrenamiento**

### ğŸ““ **CÃ³digo del Data Scientist (Notebook)**

- âœ… ExperimentaciÃ³n interactiva con mÃºltiples modelos
- âœ… GridSearch manual y comparaciÃ³n visual
- âœ… AnÃ¡lisis exploratorio de caracterÃ­sticas
- âŒ CÃ³digo no reutilizable entre experimentos
- âŒ ConfiguraciÃ³n hardcodeada
- âŒ Sin gestiÃ³n automÃ¡tica de artefactos
- âŒ DifÃ­cil de integrar en CI/CD

### ğŸ”§ **CÃ³digo del MLOps Engineer (Script)**

- âœ… **Configurable**: Todo parametrizado via YAML
- âœ… **Reproducible**: Mismo resultado en cualquier ambiente
- âœ… **Traceable**: Logging completo con MLflow
- âœ… **Automatizable**: CLI para integraciÃ³n CI/CD
- âœ… **Versionado**: GestiÃ³n automÃ¡tica de modelos
- âœ… **Auditoria**: MÃ©tricas y metadatos registrados

## ğŸ“‹ **Flujo de ConfiguraciÃ³n YAML**

### **`configs/model_config.yaml`** (Generado por experimentaciÃ³n)

```yaml
model:
  name: house_price_model
  best_model: RandomForest # Resultado de experimentaciÃ³n
  parameters:
    n_estimators: 200
    max_depth: 15
    min_samples_split: 5
    min_samples_leaf: 2
    random_state: 42
  r2_score: 0.8756
  mae: 15234.67
  target_variable: price
  feature_sets:
    rfe:
      - sqft
      - house_age
      - bedrooms
      - bathrooms
      - price_per_sqft
      - bed_bath_ratio
      - location_Suburb
      - condition_Good
      - year_built
      - condition_Excellent
    rfe_method: RandomForestRegressor
    total_features: 25
    selected_features_count: 10
```

## ğŸš€ **Ejecutar el Pipeline de Entrenamiento**

### 1. **Asegurar que MLflow estÃ© ejecutÃ¡ndose:**

```bash
cd deployment/mlflow
docker compose up -d
```

### 2. **Ejecutar entrenamiento de producciÃ³n:**

```bash
python src/models/train_model.py \
  --config configs/model_config.yaml \
  --data data/processed/featured_house_data.csv \
  --models-dir models \
  --mlflow-tracking-uri http://localhost:5555
```

### 3. **Output esperado:**

```
2025-07-24 14:30:15 - INFO - Loading config from configs/model_config.yaml
2025-07-24 14:30:15 - INFO - Loading data from data/processed/featured_house_data.csv
2025-07-24 14:30:15 - INFO - Using 10 selected features
2025-07-24 14:30:15 - INFO - Data split: Train (800, 10), Test (200, 10)
2025-07-24 14:30:15 - INFO - Created RandomForest model with parameters: {'n_estimators': 200, 'max_depth': 15, ...}
2025-07-24 14:30:16 - INFO - Training model...
2025-07-24 14:30:18 - INFO - Model performance - RÂ²: 0.8756, MAE: 15234.67, RMSE: 19876.43
2025-07-24 14:30:18 - INFO - âœ… Model saved to models/trained/house_price_model.pkl
2025-07-24 14:30:19 - INFO - âœ… Model promoted to Production stage in MLflow
2025-07-24 14:30:19 - INFO - âœ… Model logged to MLflow with run_id: a1b2c3d4e5f6
2025-07-24 14:30:19 - INFO - ğŸš€ Training pipeline completed successfully!
```

## ğŸ“¦ **Archivos Generados**

### 1. **`models/trained/house_price_model.pkl`**

```python
# Modelo entrenado serializado con joblib
import joblib
model = joblib.load('models/trained/house_price_model.pkl')
predictions = model.predict(X_new)
```

### 2. **MLflow Model Registry**

- ğŸ”„ **Experiment**: "House Price Prediction - Production"
- ğŸ·ï¸ **Model Name**: "house_price_model"
- ğŸ¯ **Stage**: "Production" (si RÂ² > 0.8)
- ğŸ“Š **Metrics**: MAE, RÂ², RMSE registradas
- ğŸ”§ **Parameters**: HyperparÃ¡metros del modelo
- ğŸ“‹ **Artifacts**: Modelo serializado

## ğŸ”„ **IntegraciÃ³n con el Pipeline MLOps**

### **1. Data Processing â†’ Feature Engineering â†’ Model Training**

```bash
# Pipeline completo automatizado
python src/data/run_processing.py \
  --input data/raw/house_data.csv \
  --output data/processed/cleaned_house_data.csv

python src/features/engineer.py \
  --input data/processed/cleaned_house_data.csv \
  --output data/processed/featured_house_data.csv \
  --preprocessor models/trained/preprocessor.pkl

python src/models/train_model.py \
  --config configs/model_config.yaml \
  --data data/processed/featured_house_data.csv \
  --models-dir models \
  --mlflow-tracking-uri http://localhost:5555
```

### **2. Para usar el modelo entrenado en la API:**

```python
# En src/api/inference.py
import joblib

model = joblib.load('models/trained/house_price_model.pkl')
preprocessor = joblib.load('models/trained/preprocessor.pkl')

def predict(raw_features):
    # Transformar caracterÃ­sticas
    features_transformed = preprocessor.transform([raw_features])
    # Hacer predicciÃ³n
    prediction = model.predict(features_transformed)
    return prediction[0]
```

## âœ… **Beneficios del Script de ProducciÃ³n**

1. **ğŸ¯ ConfiguraciÃ³n Declarativa**: Todo en YAML, fÃ¡cil de modificar
2. **ğŸ”„ Reproducibilidad**: Mismos resultados en cualquier ambiente
3. **ğŸ“Š Trazabilidad**: MLflow registra todo automÃ¡ticamente
4. **âš¡ AutomatizaciÃ³n**: CLI lista para CI/CD
5. **ğŸ›¡ï¸ ValidaciÃ³n**: MÃ©tricas y promociÃ³n automÃ¡tica
6. **ğŸ”§ Mantenimiento**: Logging y manejo de errores robusto

---

## ğŸ”® **PrÃ³ximos Pasos**

En los siguientes tutoriales del pipeline MLOps cubriremos:

- **Tutorial 4**: API REST con FastAPI (âœ… Ya existe)
- **Tutorial 5**: App de demostraciÃ³n con Streamlit (âœ… Ya existe)
- **Tutorial 6**: CI/CD Pipeline con GitHub Actions
- **Tutorial 7**: Deployment en Kubernetes

**Â¡El Model Training automatizado es el corazÃ³n del pipeline MLOps!** ğŸš€
