# ğŸš€ Tutorial MLOps: De Notebooks a ProducciÃ³n

## ğŸ“‹ Tabla de Responsabilidades

| Entregable                     | Responsable         |
| ------------------------------ | ------------------- |
| ğŸ““ Notebooks de entrenamiento  | CientÃ­fico de datos |
| ğŸ”§ Scripts limpios y modulares | Ingeniero de MLOps  |
| ğŸ¤– Modelo + preprocesador      | Ingeniero de MLOps  |
| ğŸŒ API REST (FastAPI)          | Ingeniero de MLOps  |
| ğŸ“± App prototipo (Streamlit)   | Ingeniero de MLOps  |
| ğŸ³ Dockerfile + Compose        | Ingeniero de MLOps  |

---

## ğŸ¯ Paso 1: Convertir Notebook a Script Modular

### ğŸ“š **Â¿QuÃ© recibe el MLOps Engineer?**

El cientÃ­fico de datos entrega un notebook `02_feature_engineering.ipynb` con:

```python
# ğŸ““ CÃ³digo del Data Scientist en Jupyter
import pandas as pd
import numpy as np
from datetime import datetime

# Carga de datos
df = pd.read_csv("../data/processed/cleaned_house_data.csv")

# Feature Engineering exploratorio
df['house_age'] = datetime.now().year - df['year_built']
df['price_per_sqft'] = df['price'] / df['sqft']
df['bed_bath_ratio'] = df['bedrooms'] / df['bathrooms']

# Visualizaciones y anÃ¡lisis...
```

### âš¡ **TransformaciÃ³n a Script de ProducciÃ³n**

El MLOps Engineer convierte esto en `src/features/engineer.py`:

```python
# ğŸ”§ Script de ProducciÃ³n del MLOps Engineer
import pandas as pd
import numpy as np
from datetime import datetime
import logging
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
import joblib

# ConfiguraciÃ³n de logging profesional
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('feature-engineering')

def create_features(df):
    """FunciÃ³n modular para crear caracterÃ­sticas."""
    logger.info("Creating new features")
    df_featured = df.copy()

    # Feature 1: Edad de la casa
    current_year = datetime.now().year
    df_featured['house_age'] = current_year - df_featured['year_built']
    logger.info("Created 'house_age' feature")

    # Feature 2: Precio por pie cuadrado
    df_featured['price_per_sqft'] = df_featured['price'] / df_featured['sqft']
    logger.info("Created 'price_per_sqft' feature")

    # Feature 3: Ratio de habitaciones/baÃ±os
    df_featured['bed_bath_ratio'] = df_featured['bedrooms'] / df_featured['bathrooms']
    df_featured['bed_bath_ratio'] = df_featured['bed_bath_ratio'].replace([np.inf, -np.inf], np.nan)
    df_featured['bed_bath_ratio'] = df_featured['bed_bath_ratio'].fillna(0)
    logger.info("Created 'bed_bath_ratio' feature")

    return df_featured

def create_preprocessor():
    """Pipeline de preprocesamiento para producciÃ³n."""
    logger.info("Creating preprocessor pipeline")

    # CaracterÃ­sticas categÃ³ricas y numÃ©ricas
    categorical_features = ['location', 'condition']
    numerical_features = ['sqft', 'bedrooms', 'bathrooms', 'house_age', 'price_per_sqft', 'bed_bath_ratio']

    # Pipeline para caracterÃ­sticas numÃ©ricas
    numerical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='mean'))
    ])

    # Pipeline para caracterÃ­sticas categÃ³ricas
    categorical_transformer = Pipeline(steps=[
        ('onehot', OneHotEncoder(handle_unknown='ignore'))
    ])

    # Combinador de transformadores
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numerical_transformer, numerical_features),
            ('cat', categorical_transformer, categorical_features)
        ]
    )

    return preprocessor

def run_feature_engineering(input_file, output_file, preprocessor_file):
    """Pipeline completo de feature engineering."""
    # Cargar datos
    logger.info(f"Loading data from {input_file}")
    df = pd.read_csv(input_file)

    # Crear caracterÃ­sticas
    df_featured = create_features(df)
    logger.info(f"Created featured dataset with shape: {df_featured.shape}")

    # Crear y entrenar preprocessor
    preprocessor = create_preprocessor()
    X = df_featured.drop(columns=['price'], errors='ignore')
    y = df_featured['price'] if 'price' in df_featured.columns else None

    # Entrenar y transformar
    X_transformed = preprocessor.fit_transform(X)
    logger.info("Fitted the preprocessor and transformed the features")

    # Guardar preprocessor entrenado
    joblib.dump(preprocessor, preprocessor_file)
    logger.info(f"Saved preprocessor to {preprocessor_file}")

    # Guardar datos transformados
    df_transformed = pd.DataFrame(X_transformed)
    if y is not None:
        df_transformed['price'] = y.values
    df_transformed.to_csv(output_file, index=False)
    logger.info(f"Saved fully preprocessed data to {output_file}")

    return df_transformed

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Feature engineering for housing data.')
    parser.add_argument('--input', required=True, help='Path to cleaned CSV file')
    parser.add_argument('--output', required=True, help='Path for output CSV file')
    parser.add_argument('--preprocessor', required=True, help='Path for saving the preprocessor')

    args = parser.parse_args()

    run_feature_engineering(args.input, args.output, args.preprocessor)
```

## ğŸ”‘ **Diferencias Clave: Notebook vs Script de ProducciÃ³n**

### ğŸ““ **CÃ³digo del Data Scientist (Notebook)**

- âœ… Exploratorio y experimental
- âœ… Visualizaciones inline
- âœ… AnÃ¡lisis paso a paso
- âŒ CÃ³digo no reutilizable
- âŒ Rutas hardcodeadas
- âŒ Sin manejo de errores
- âŒ DifÃ­cil de automatizar

### ğŸ”§ **CÃ³digo del MLOps Engineer (Script)**

- âœ… **Modular**: Funciones separadas y reutilizables
- âœ… **Configurable**: Argumentos de lÃ­nea de comandos
- âœ… **Robusto**: Logging y manejo de errores
- âœ… **Reproducible**: Pipeline determinÃ­stico
- âœ… **Escalable**: FÃ¡cil integraciÃ³n en CI/CD
- âœ… **Reutilizable**: Mismo preprocessor en entrenamiento y producciÃ³n

## ğŸš€ **Ejecutar el Script de ProducciÃ³n**

### 1. **Crear estructura de directorios:**

```bash
mkdir -p data/processed models/trained
```

### 2. **Ejecutar feature engineering:**

```bash
python src/features/engineer.py \
  --input data/processed/cleaned_house_data.csv \
  --output data/processed/featured_house_data.csv \
  --preprocessor models/trained/preprocessor.pkl
```

### 3. **Output esperado:**

```
2025-01-23 10:30:15 - feature-engineering - INFO - Loading data from data/processed/cleaned_house_data.csv
2025-01-23 10:30:15 - feature-engineering - INFO - Creating new features
2025-01-23 10:30:15 - feature-engineering - INFO - Created 'house_age' feature
2025-01-23 10:30:15 - feature-engineering - INFO - Created 'price_per_sqft' feature
2025-01-23 10:30:15 - feature-engineering - INFO - Created 'bed_bath_ratio' feature
2025-01-23 10:30:15 - feature-engineering - INFO - Created featured dataset with shape: (1000, 9)
2025-01-23 10:30:15 - feature-engineering - INFO - Creating preprocessor pipeline
2025-01-23 10:30:15 - feature-engineering - INFO - Fitted the preprocessor and transformed the features
2025-01-23 10:30:15 - feature-engineering - INFO - Saved preprocessor to models/trained/preprocessor.pkl
2025-01-23 10:30:15 - feature-engineering - INFO - Saved fully preprocessed data to data/processed/featured_house_data.csv
```

## ğŸ“¦ **Archivos Generados**

### 1. **`featured_house_data.csv`**

```csv
# Datos transformados listos para ML
sqft,bedrooms,bathrooms,house_age,price_per_sqft,bed_bath_ratio,location_City,location_Suburb,condition_Fair,condition_Good,price
1500.0,3.0,2.0,34.0,166.67,1.5,0.0,1.0,0.0,1.0,250000
```

### 2. **`preprocessor.pkl`**

- Pipeline de sklearn serializado
- Contiene todas las transformaciones aprendidas
- Listo para usar en producciÃ³n y APIs

## ğŸ¯ **Â¿Por quÃ© es importante el preprocessor.pkl?**

### **En Entrenamiento:**

```python
# El preprocessor aprende las transformaciones
preprocessor.fit(X_train)  # Aprende medias, categorÃ­as, etc.
X_train_transformed = preprocessor.transform(X_train)
model.fit(X_train_transformed, y_train)
```

### **En ProducciÃ³n:**

```python
# El mismo preprocessor transforma datos nuevos
import joblib
preprocessor = joblib.load('models/trained/preprocessor.pkl')
X_new_transformed = preprocessor.transform(X_new)  # Mismas transformaciones
predictions = model.predict(X_new_transformed)
```

## âœ… **Beneficios de esta TransformaciÃ³n**

1. **ğŸ”„ Reproducibilidad**: Mismo resultado siempre
2. **âš¡ AutomatizaciÃ³n**: Integrable en pipelines CI/CD
3. **ğŸ›¡ï¸ Robustez**: Manejo de errores y logging
4. **ğŸ“ˆ Escalabilidad**: Procesa cualquier volumen de datos
5. **ğŸ”§ Mantenibilidad**: CÃ³digo limpio y modular
6. **ğŸ¯ Consistencia**: Mismas transformaciones en entrenamiento y producciÃ³n

---

## ğŸ”® **PrÃ³ximos Pasos**

En los siguientes pasos del tutorial cubriremos:

- **Paso 2**: Script de entrenamiento modular (`train_model.py`)
- **Paso 3**: API REST con FastAPI
- **Paso 4**: App de demostraciÃ³n con Streamlit
- **Paso 5**: ContainerizaciÃ³n con Docker
- **Paso 6**: OrquestaciÃ³n con Docker Compose

**Â¡El MLOps Engineer transforma experimentos en sistemas de producciÃ³n robustos!** ğŸš€
