# 🛠️ Monitoreo de FastAPI con Prometheus y Grafana

## 🎯 Objetivo

Instrumentar una API en **FastAPI** para recolectar métricas con **Prometheus** y visualizarlas en **Grafana**.

---

## 🧩 Estructura del entorno

```
mlops-lab/
├── docker-compose.yml
├── prometheus/
│   └── prometheus.yml
├── app/
│   └── main.py
│   └── requirements.txt
```

## Arquitectura:

Arquitectura Docker Compose: MLOps App con Prometheus y Grafana

```
+---------------------------+
|      Usuario Final        |
+---------------------------+
           |
           v
+---------------------------+
|     Frontend: Streamlit   |
| - Imagen: pytuxi/house... |
| - Puerto: 8501            |
+---------------------------+
           |
           v
+---------------------------+
|     Backend: FastAPI      |
| - Imagen: pytuxi/house... |
| - Puerto: 8000            |
| - Instrumentado con       |
|   prometheus_fastapi_...  |
+---------------------------+
           |
           v
+---------------------------+
|  Prometheus (9090)        |
| - Pull a /metrics de API  |
| - Config: prometheus.yml  |
+---------------------------+
           |
           v
+---------------------------+
|     Grafana (3000)        |
| - Dashboards desde Prom   |
+---------------------------+
```

---

```mermaid
flowchart TD
    subgraph Frontend
        streamlit[Streamlit App<br>pytuxi/house-price-streamlit]
    end

    subgraph Backend
        api[FastAPI API<br>pytuxi/house-price-model]
    end

    subgraph Monitoring
        prometheus[Prometheus<br>prom/prometheus]
        grafana[Grafana<br>grafana/grafana]
    end

    subgraph Monitoring_Config
        prometheus_cfg[prometheus.yml]
    end

    streamlit -->|requests| api
    api -->|metrics /metrics| prometheus
    prometheus_cfg --> prometheus
    prometheus --> grafana
    grafana -->|dashboards| user[(User)]
    prometheus -->|Web UI| prometheus_ui[Prometheus UI]

    user -->|access| streamlit
    user -->|access| grafana
```

---

## ✅ 1. API FastAPI con Prometheus Instrumentation

### 📄 `src/api/main.py`

```python
from fastapi import FastAPI
from prometheus_fastapi_instrumentator import Instrumentator # agregar este imort

app = FastAPI(
    title="House Price Prediction API",
    description=(
        "An API for predicting house prices based on various features. "
        "This application is part of the MLOps Bootcamp by School of Devops. "
        "Authored by Gourav Shah."
    ),
    version="1.0.0",
    contact={
        "name": "School of Devops",
        "url": "https://schoolofdevops.com",
        "email": "learn@schoolofdevops.com",
    },
    license_info={
        "name": "Apache 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.html",
    },
)

Instrumentator().instrument(app).expose(app) # agregar esta configuracion

# dejar codigo existente que sigue como app.add_middleware(...)

```

### 📄 `src/api/requirements.txt`

```
prometheus-fastapi-instrumentator
```

---

## ⚙️ 2. Configuraciones previas necesarias

Para que el monitoreo funcione correctamente en Docker Compose, necesitas realizar algunos ajustes:

### � Cambio en Streamlit App (si aplica)

**Archivo**: `streamlit_app/app.py`

**Antes:**

```python
api_endpoint = os.getenv("API_URL", "http://localhost:8000")
```

**Después:**

```python
api_endpoint = os.getenv("API_URL", "http://api:8000")
```

**¿Por qué?** En Docker Compose, los contenedores se comunican usando el **nombre del servicio**, no `localhost`.

### 🔄 Cambio en Dockerfile de la API

**Archivo**: `Dockerfile`

**Antes:**

```dockerfile
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Después:**

```dockerfile
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "80"]
```

**¿Por qué?** Para alinear con el mapeo de puertos en docker-compose: `8000:80` (host:contenedor).

---

## �🐳 3. Dockerización de los servicios

### 📄 `docker-compose.yml`

```yaml
version: "3.8"

services:
  api:
    image: pytuxi/house-price-model:v1.0.3
    ports:
      - "8000:80"

  streamlit:
    image: pytuxi/house-price-streamlit:v1.0.1
    ports:
      - "8501:8501"
    depends_on:
      - api

  prometheus:
    image: prom/prometheus:v2.52.0
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:10.2.2
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
```

---

## 📊 4. Configuración de Prometheus

### 📄 `monitoring/prometheus/prometheus.yml`

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: "fastapi"
    static_configs:
      - targets: ["api:80"] # Nombre del servicio + puerto interno
```

**⚠️ Importante**: Usar `api:80` (nombre del servicio + puerto interno del contenedor), no `localhost:8000`.

---

## � Comunicación entre contenedores

### 📊 Diagrama de red interna:

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Streamlit     │───▶│      API        │◀───│   Prometheus    │
│ (streamlit:8501)│    │   (api:80)      │    │ (prometheus:9090│
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────────────────────────────────────────────────────┐
│                    Red Docker Compose                          │
│   Puertos externos: 8501, 8000, 9090, 3000                   │
└─────────────────────────────────────────────────────────────────┘
```

### 🎯 Comparación: Local vs Docker Compose

| Componente             | Desarrollo Local        | Docker Compose          |
| ---------------------- | ----------------------- | ----------------------- |
| **Streamlit → API**    | `http://localhost:8000` | `http://api:8000`       |
| **Prometheus → API**   | `localhost:8000`        | `api:80`                |
| **Tu navegador → API** | `http://localhost:8000` | `http://localhost:8000` |
| **Puerto interno API** | `8000`                  | `80`                    |

---

## �🚀 5. Levantar los servicios

```bash
docker-compose -f deployment/docker-compose/docker-compose.yaml up -d
```

---

## 🔍 6. Validaciones

### 🔸 Prometheus

Navega a:

```
http://localhost:9090/targets
```

Consulta métricas como:

```
http_requests_total
process_cpu_seconds_total
```

### 🔸 Grafana

1. Ir a: `http://localhost:3000`
2. Usuario/contraseña: `admin / admin`
3. Configurar datasource:
   - **Type**: Prometheus
   - **URL**: `http://prometheus:9090`
4. Guardar y testear

---

## 📈 7. Crear un dashboard en Grafana

1. `+ Create` → Dashboard → Add Panel
2. En “Query”:
   ```
   http_server_requests_total{job="fastapi"}
   ```
3. Visualiza en formato **Time Series**

---

## 🧪 8. Simular tráfico

```bash
curl http://localhost:8000/
curl http://localhost:8000/predict
```

---

## 🧼 9. Para detener

```bash
docker-compose down
```

---

## 📊 10. Importar y personalizar el dashboard de Grafana (ID: 15834)

Grafana proporciona un dashboard listo para usar con FastAPI:  
👉 [https://grafana.com/grafana/dashboards/15834-fastapi](https://grafana.com/grafana/dashboards/15834-fastapi)

### 📥 Pasos para importar:

1. Ir a Grafana `http://localhost:3000`
2. Menú lateral → **+ Create → Import**
3. En "Import via grafana.com", ingresa el ID: `15834`
4. Click en **Load**
5. Selecciona el datasource Prometheus configurado
6. Click en **Import**

---

## 📈 11. Indicadores clave del dashboard

Aquí algunos paneles útiles incluidos (y cómo actualizarlos si fuera necesario):

### 🔸 Request per second (total)

```promql
rate(http_server_requests_total{job="fastapi"}[1m])
```

> Si no ves datos, aumenta el rango a `[5m]`.

### 🔸 Request duration (latencia)

```promql
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="fastapi"}[5m]))
```

### 🔸 CPU Usage (seconds per second)

```promql
rate(process_cpu_seconds_total{job="fastapi"}[1m])
```

Multiplica por 100 si quieres verlo en `%` para 1 core.

### 🔸 Porcentaje de respuestas exitosas (2xx)

```promql
sum(rate(http_server_requests_total{job="fastapi", status=~"2.."}[1m]))
/
sum(rate(http_server_requests_total{job="fastapi"}[1m]))
```

### 🔸 Códigos 4xx y 5xx

```promql
sum(rate(http_server_requests_total{job="fastapi", status=~"4.."}[1m]))
```

```promql
sum(rate(http_server_requests_total{job="fastapi", status=~"5.."}[1m]))
```

---

## 🧪 12. Sugerencia de tráfico para alimentar las métricas

Usa el script `generate_traffic.py` para enviar solicitudes `GET /` y `POST /predict` automáticamente y observar cómo se llenan los paneles en tiempo real.

---
