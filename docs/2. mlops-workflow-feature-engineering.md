# ğŸ§  Tutorial MLOps: Feature Engineering de ProducciÃ³n

## ğŸ“‹ Tabla de Responsabilidades

| Entregable                        | Responsable         | Status               |
| --------------------------------- | ------------------- | -------------------- |
| ğŸ““ ExploraciÃ³n de caracterÃ­sticas | CientÃ­fico de datos | âœ… Completo          |
| ğŸ”§ Pipeline de transformaciÃ³n     | Ingeniero de MLOps  | ğŸ¯ **Este tutorial** |
| ğŸ¤– Preprocessor serializado       | Ingeniero de MLOps  | ğŸ¯ **Este tutorial** |
| ğŸ“Š Features listas para ML        | Ingeniero de MLOps  | ğŸ¯ **Este tutorial** |
| ğŸ”„ Script reutilizable            | Ingeniero de MLOps  | ğŸ¯ **Este tutorial** |

---

# ğŸ“˜ MLOps Workflow: Feature Engineering desde Notebook a Script

### ğŸ“š **Â¿QuÃ© recibe el MLOps Engineer?**

El cientÃ­fico de datos entrega un notebook `02_feature_engineering.ipynb` con:

```python
# ğŸ““ CÃ³digo exploratorio del Data Scientist
import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns

# Carga y exploraciÃ³n
df = pd.read_csv("../data/processed/cleaned_house_data.csv")
print(f"Dataset shape: {df.shape}")
df.head()

# Feature Engineering exploratorio
df['house_age'] = 2025 - df['year_built']
df['price_per_sqft'] = df['price'] / df['sqft']
df['bed_bath_ratio'] = df['bedrooms'] / df['bathrooms']

# AnÃ¡lisis de correlaciones
plt.figure(figsize=(12, 8))
correlation_matrix = df[['price', 'sqft', 'house_age', 'price_per_sqft', 'bed_bath_ratio']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.show()

# Encoding categÃ³rico manual
df_encoded = pd.get_dummies(df, columns=['location', 'condition'])

# NormalizaciÃ³n bÃ¡sica
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
numeric_cols = ['sqft', 'bedrooms', 'bathrooms', 'house_age', 'price_per_sqft', 'bed_bath_ratio']
df_encoded[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])
```

### âš¡ **TransformaciÃ³n a Pipeline de ProducciÃ³n**

El MLOps Engineer convierte esto en `src/features/engineer.py`:

```python
# ğŸ”§ Pipeline de ProducciÃ³n del MLOps Engineer
import pandas as pd
import numpy as np
from datetime import datetime
import logging
import joblib
from pathlib import Path
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.base import BaseEstimator, TransformerMixin

# ConfiguraciÃ³n de logging profesional
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('feature-engineering')

class HouseFeaturesEngineer(BaseEstimator, TransformerMixin):
    """
    Transformador personalizado para feature engineering de casas.
    Crea caracterÃ­sticas derivadas especÃ­ficas del dominio inmobiliario.
    """

    def __init__(self, current_year=None):
        self.current_year = current_year or datetime.now().year

    def fit(self, X, y=None):
        """Aprende parÃ¡metros necesarios del dataset de entrenamiento."""
        logger.info("Fitting HouseFeaturesEngineer")

        # Calcular estadÃ­sticas para features derivadas
        if 'sqft' in X.columns and 'bedrooms' in X.columns:
            self.median_sqft_per_bedroom = X['sqft'].median() / X['bedrooms'].median()
        else:
            self.median_sqft_per_bedroom = 500  # Default fallback

        return self

    def transform(self, X):
        """Aplica las transformaciones de feature engineering."""
        logger.info("Transforming features with HouseFeaturesEngineer")
        X_transformed = X.copy()

        # Feature 1: Edad de la casa
        if 'year_built' in X_transformed.columns:
            X_transformed['house_age'] = self.current_year - X_transformed['year_built']
            logger.info("âœ… Created 'house_age' feature")

        # Feature 2: Ratio habitaciones/baÃ±os
        if 'bedrooms' in X_transformed.columns and 'bathrooms' in X_transformed.columns:
            # Manejar divisiÃ³n por cero
            X_transformed['bed_bath_ratio'] = X_transformed['bedrooms'] / X_transformed['bathrooms'].replace(0, np.nan)
            X_transformed['bed_bath_ratio'] = X_transformed['bed_bath_ratio'].fillna(X_transformed['bedrooms'])
            logger.info("âœ… Created 'bed_bath_ratio' feature")

        # Feature 3: Superficie por habitaciÃ³n
        if 'sqft' in X_transformed.columns and 'bedrooms' in X_transformed.columns:
            X_transformed['sqft_per_bedroom'] = X_transformed['sqft'] / X_transformed['bedrooms'].replace(0, 1)
            logger.info("âœ… Created 'sqft_per_bedroom' feature")

        # Feature 4: Es casa nueva? (menos de 5 aÃ±os)
        if 'house_age' in X_transformed.columns:
            X_transformed['is_new_house'] = (X_transformed['house_age'] <= 5).astype(int)
            logger.info("âœ… Created 'is_new_house' feature")

        # Feature 5: Es casa grande? (mÃ¡s de 2000 sqft)
        if 'sqft' in X_transformed.columns:
            X_transformed['is_large_house'] = (X_transformed['sqft'] > 2000).astype(int)
            logger.info("âœ… Created 'is_large_house' feature")

        # Feature 6: CategorÃ­a de ubicaciÃ³n simplificada
        if 'location' in X_transformed.columns:
            location_mapping = {
                'Downtown': 'Urban',
                'Urban': 'Urban',
                'Suburb': 'Suburban',
                'Rural': 'Rural',
                'Waterfront': 'Premium',
                'Mountain': 'Premium'
            }
            X_transformed['location_category'] = X_transformed['location'].map(location_mapping).fillna('Other')
            logger.info("âœ… Created 'location_category' feature")

        # Remover columnas originales que ya no necesitamos
        columns_to_drop = ['year_built']  # Mantenemos location original para OneHotEncoder
        X_transformed = X_transformed.drop(columns=[col for col in columns_to_drop if col in X_transformed.columns])

        logger.info(f"Feature engineering completed. New shape: {X_transformed.shape}")
        return X_transformed

def create_feature_engineering_pipeline():
    """
    Crea el pipeline completo de feature engineering para producciÃ³n.

    Returns:
        sklearn.pipeline.Pipeline: Pipeline completo de transformaciÃ³n
    """
    logger.info("Creating feature engineering pipeline")

    # Definir columnas por tipo
    # Estas se actualizarÃ¡n despuÃ©s del feature engineering
    original_numeric = ['sqft', 'bedrooms', 'bathrooms', 'price_per_sqft']
    derived_numeric = ['house_age', 'bed_bath_ratio', 'sqft_per_bedroom']
    binary_features = ['is_new_house', 'is_large_house']
    categorical_features = ['location', 'condition', 'location_category']

    # Todas las caracterÃ­sticas numÃ©ricas (originales + derivadas + binarias)
    all_numeric = original_numeric + derived_numeric + binary_features

    # Pipeline para caracterÃ­sticas numÃ©ricas
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])

    # Pipeline para caracterÃ­sticas categÃ³ricas
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ])

    # Combinador de transformadores
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, all_numeric),
            ('cat', categorical_transformer, categorical_features)
        ],
        remainder='drop'  # Eliminar columnas no especificadas
    )

    # Pipeline completo: Feature Engineering + Preprocessing
    pipeline = Pipeline(steps=[
        ('feature_engineer', HouseFeaturesEngineer()),
        ('preprocessor', preprocessor)
    ])

    logger.info("âœ… Feature engineering pipeline created")
    return pipeline

def validate_features(df):
    """Valida que el DataFrame tenga las columnas requeridas."""
    required_columns = ['sqft', 'bedrooms', 'bathrooms', 'location', 'year_built', 'condition']

    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        raise ValueError(f"Missing required columns: {missing_columns}")

    logger.info("âœ… Feature validation passed")
    return True

def generate_feature_report(X_original, X_transformed, feature_names):
    """Genera un reporte de las caracterÃ­sticas creadas."""
    report = {
        'original_features': X_original.shape[1],
        'transformed_features': X_transformed.shape[1],
        'feature_names': feature_names,
        'transformation_ratio': X_transformed.shape[1] / X_original.shape[1]
    }

    logger.info(f"ğŸ“Š Feature Report:")
    logger.info(f"   Original features: {report['original_features']}")
    logger.info(f"   Transformed features: {report['transformed_features']}")
    logger.info(f"   Transformation ratio: {report['transformation_ratio']:.2f}x")

    return report

def run_feature_engineering(input_file, output_file, preprocessor_file):
    """
    Pipeline completo de feature engineering para producciÃ³n.

    Args:
        input_file (str): Ruta al archivo CSV de datos limpios
        output_file (str): Ruta para guardar datos con features
        preprocessor_file (str): Ruta para guardar el pipeline serializado
    """
    try:
        # 1. Cargar datos limpios
        logger.info(f"ğŸ“ Loading cleaned data from {input_file}")
        df = pd.read_csv(input_file)
        logger.info(f"âœ… Loaded dataset with shape: {df.shape}")

        # 2. Validar estructura de datos
        validate_features(df)

        # 3. Separar caracterÃ­sticas y target
        target_column = 'price'
        if target_column in df.columns:
            X = df.drop(columns=[target_column])
            y = df[target_column]
            logger.info(f"âœ… Separated features (X) and target (y)")
        else:
            X = df
            y = None
            logger.warning(f"âš ï¸ Target column '{target_column}' not found. Proceeding with feature engineering only.")

        # 4. Crear y entrenar pipeline
        logger.info("ğŸ”§ Creating and fitting feature engineering pipeline")
        pipeline = create_feature_engineering_pipeline()

        # 5. Ajustar pipeline y transformar datos
        X_transformed = pipeline.fit_transform(X)

        # 6. Obtener nombres de caracterÃ­sticas despuÃ©s de la transformaciÃ³n
        # Esto es complejo debido a OneHotEncoder, pero podemos aproximarlo
        try:
            feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()
        except:
            feature_names = [f'feature_{i}' for i in range(X_transformed.shape[1])]

        logger.info(f"âœ… Feature engineering completed. Shape: {X_transformed.shape}")

        # 7. Generar reporte de transformaciÃ³n
        generate_feature_report(X, X_transformed, feature_names)

        # 8. Guardar pipeline entrenado
        logger.info(f"ğŸ’¾ Saving trained pipeline to {preprocessor_file}")

        # Crear directorio si no existe
        Path(preprocessor_file).parent.mkdir(parents=True, exist_ok=True)

        joblib.dump(pipeline, preprocessor_file)
        logger.info(f"âœ… Pipeline saved successfully")

        # 9. Preparar datos finales para guardar
        df_output = pd.DataFrame(X_transformed, columns=feature_names)

        # Agregar target si existe
        if y is not None:
            df_output[target_column] = y.values

        # 10. Guardar datos transformados
        logger.info(f"ğŸ’¾ Saving transformed data to {output_file}")

        # Crear directorio si no existe
        Path(output_file).parent.mkdir(parents=True, exist_ok=True)

        df_output.to_csv(output_file, index=False)
        logger.info(f"âœ… Transformed data saved successfully")

        # 11. Resumen final
        logger.info("ğŸ‰ Feature engineering pipeline completed successfully!")
        logger.info(f"ğŸ“Š Summary:")
        logger.info(f"   Input: {input_file} ({df.shape})")
        logger.info(f"   Output: {output_file} ({df_output.shape})")
        logger.info(f"   Pipeline: {preprocessor_file}")

        return df_output

    except Exception as e:
        logger.error(f"âŒ Error in feature engineering pipeline: {str(e)}")
        raise

def test_pipeline(preprocessor_file, sample_data=None):
    """
    FunciÃ³n para testear el pipeline guardado con datos de muestra.

    Args:
        preprocessor_file (str): Ruta al pipeline serializado
        sample_data (dict, optional): Datos de muestra para testear
    """
    logger.info("ğŸ§ª Testing saved pipeline")

    # Cargar pipeline
    pipeline = joblib.load(preprocessor_file)
    logger.info("âœ… Pipeline loaded successfully")

    # Datos de muestra si no se proporcionan
    if sample_data is None:
        sample_data = {
            'sqft': [1500, 2000, 1200],
            'bedrooms': [3, 4, 2],
            'bathrooms': [2, 3, 1],
            'location': ['Suburb', 'Urban', 'Rural'],
            'year_built': [2000, 1985, 2010],
            'condition': ['Good', 'Excellent', 'Fair'],
            'price_per_sqft': [200, 250, 180]
        }

    # Crear DataFrame de prueba
    test_df = pd.DataFrame(sample_data)
    logger.info(f"âœ… Created test data with shape: {test_df.shape}")

    # Transformar datos de prueba
    transformed = pipeline.transform(test_df)
    logger.info(f"âœ… Test transformation successful. Output shape: {transformed.shape}")

    return transformed

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='Feature engineering pipeline for house price prediction')
    parser.add_argument('--input', required=True, help='Path to cleaned CSV file')
    parser.add_argument('--output', required=True, help='Path for output CSV file with engineered features')
    parser.add_argument('--preprocessor', required=True, help='Path for saving the trained preprocessing pipeline')
    parser.add_argument('--test', action='store_true', help='Run pipeline test after training')

    args = parser.parse_args()

    # Ejecutar pipeline principal
    run_feature_engineering(args.input, args.output, args.preprocessor)

    # Ejecutar test si se solicita
    if args.test:
        logger.info("ğŸ§ª Running pipeline test")
        test_pipeline(args.preprocessor)
        logger.info("âœ… Pipeline test completed successfully")
```

## ğŸ”‘ **Diferencias Clave: ExploraciÃ³n vs Script**

### ğŸ““ **CÃ³digo del Data Scientist (Notebook)**

```python
# âŒ CÃ³digo exploratorio - No apto para producciÃ³n
df['house_age'] = 2025 - df['year_built']  # AÃ±o hardcodeado
df['bed_bath_ratio'] = df['bedrooms'] / df['bathrooms']  # Sin manejo de divisiÃ³n por 0
df_encoded = pd.get_dummies(df, columns=['location'])  # Sin handle_unknown
scaler.fit_transform(df[numeric_cols])  # Fit y transform juntos (data leakage)
```

### ğŸ”§ **CÃ³digo del MLOps Engineer (Script)**

```python
# âœ… CÃ³digo de producciÃ³n - Robusto y escalable
class HouseFeaturesEngineer(BaseEstimator, TransformerMixin):
    def __init__(self, current_year=None):
        self.current_year = current_year or datetime.now().year  # âœ… Configurable

    def transform(self, X):
        X_transformed['bed_bath_ratio'] = X['bedrooms'] / X['bathrooms'].replace(0, np.nan)  # âœ… Manejo de divisiÃ³n por 0

Pipeline([
    ('feature_engineer', HouseFeaturesEngineer()),  # âœ… SeparaciÃ³n clara
    ('preprocessor', ColumnTransformer([
        ('onehot', OneHotEncoder(handle_unknown='ignore'))  # âœ… Manejo de categorÃ­as nuevas
    ]))
])
```

## ğŸš€ **Ejecutar el Script de Feature Engineering**

### 1. **Crear estructura de directorios:**

```bash
mkdir -p data/processed models/trained logs
```

### 2. **Ejecutar pipeline completo:**

```bash
python src/features/engineer.py \
  --input data/processed/cleaned_house_data.csv \
  --output data/processed/featured_house_data.csv \
  --preprocessor models/trained/preprocessor.pkl \
  --test
```

### 3. **Output esperado:**

```
2025-07-24 10:30:15 - feature-engineering - INFO - ğŸ“ Loading cleaned data from data/processed/cleaned_house_data.csv
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Loaded dataset with shape: (1000, 8)
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Feature validation passed
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Separated features (X) and target (y)
2025-07-24 10:30:15 - feature-engineering - INFO - ğŸ”§ Creating and fitting feature engineering pipeline
2025-07-24 10:30:15 - feature-engineering - INFO - Creating feature engineering pipeline
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Feature engineering pipeline created
2025-07-24 10:30:15 - feature-engineering - INFO - Fitting HouseFeaturesEngineer
2025-07-24 10:30:15 - feature-engineering - INFO - Transforming features with HouseFeaturesEngineer
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Created 'house_age' feature
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Created 'bed_bath_ratio' feature
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Created 'sqft_per_bedroom' feature
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Created 'is_new_house' feature
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Created 'is_large_house' feature
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Created 'location_category' feature
2025-07-24 10:30:15 - feature-engineering - INFO - Feature engineering completed. New shape: (1000, 13)
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Feature engineering completed. Shape: (1000, 25)
2025-07-24 10:30:15 - feature-engineering - INFO - ğŸ“Š Feature Report:
2025-07-24 10:30:15 - feature-engineering - INFO -    Original features: 7
2025-07-24 10:30:15 - feature-engineering - INFO -    Transformed features: 25
2025-07-24 10:30:15 - feature-engineering - INFO -    Transformation ratio: 3.57x
2025-07-24 10:30:15 - feature-engineering - INFO - ğŸ’¾ Saving trained pipeline to models/trained/preprocessor.pkl
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Pipeline saved successfully
2025-07-24 10:30:15 - feature-engineering - INFO - ğŸ’¾ Saving transformed data to data/processed/featured_house_data.csv
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Transformed data saved successfully
2025-07-24 10:30:15 - feature-engineering - INFO - ğŸ‰ Feature engineering pipeline completed successfully!
2025-07-24 10:30:15 - feature-engineering - INFO - ğŸ§ª Running pipeline test
2025-07-24 10:30:15 - feature-engineering - INFO - ğŸ§ª Testing saved pipeline
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Pipeline loaded successfully
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Created test data with shape: (3, 7)
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Test transformation successful. Output shape: (3, 25)
2025-07-24 10:30:15 - feature-engineering - INFO - âœ… Pipeline test completed successfully
```

## ğŸ“¦ **Archivos Generados**

### 1. **`featured_house_data.csv`**

```csv
# Datos transformados con todas las caracterÃ­sticas engineered
num__sqft,num__bedrooms,num__bathrooms,num__price_per_sqft,num__house_age,num__bed_bath_ratio,num__sqft_per_bedroom,num__is_new_house,num__is_large_house,cat__location_Downtown,cat__location_Mountain,cat__location_Rural,cat__location_Suburb,cat__location_Urban,cat__location_Waterfront,cat__condition_Excellent,cat__condition_Fair,cat__condition_Good,cat__condition_Poor,cat__location_category_Premium,cat__location_category_Rural,cat__location_category_Suburban,cat__location_category_Urban,price
-0.23,0.14,-0.45,1.2,0.67,0.89,-0.12,0,1,0,0,0,1,0,0,0,0,1,0,0,0,1,0,250000
```

### 2. **`preprocessor.pkl`**

- Pipeline completo de sklearn serializado
- Incluye HouseFeaturesEngineer + ColumnTransformer
- Contiene todas las transformaciones aprendidas (scaling, encoding, etc.)
- Listo para usar en producciÃ³n sin reentrenamiento

## ğŸ¯ **Â¿Por quÃ© este Script es Superior?**

### **ğŸ”„ ReutilizaciÃ³n Perfecta:**

```python
# Entrenamiento
pipeline = joblib.load('models/trained/preprocessor.pkl')
X_train_transformed = pipeline.fit_transform(X_train)
model.fit(X_train_transformed, y_train)

# ProducciÃ³n (mismas transformaciones automÃ¡ticamente)
X_new_transformed = pipeline.transform(X_new)
predictions = model.predict(X_new_transformed)
```

### **ğŸ›¡ï¸ Robustez de ProducciÃ³n:**

1. **Manejo de valores faltantes**: SimpleImputer con estrategias configurables
2. **CategorÃ­as nuevas**: OneHotEncoder con `handle_unknown='ignore'`
3. **DivisiÃ³n por cero**: Reemplazo seguro en ratios
4. **Escalabilidad**: Funciona con 1 fila o 1 millÃ³n de filas
5. **Versionado**: Pipelines serializados para control de versiones

### **ğŸ“Š CaracterÃ­sticas Creadas:**

| CaracterÃ­stica      | DescripciÃ³n               | Valor de Negocio      |
| ------------------- | ------------------------- | --------------------- |
| `house_age`         | AÃ±os desde construcciÃ³n   | Depreciation modeling |
| `bed_bath_ratio`    | Ratio habitaciones/baÃ±os  | Layout efficiency     |
| `sqft_per_bedroom`  | Superficie por habitaciÃ³n | Space optimization    |
| `is_new_house`      | Casa nueva (â‰¤5 aÃ±os)      | Premium pricing       |
| `is_large_house`    | Casa grande (>2000 sqft)  | Luxury segment        |
| `location_category` | CategorÃ­a de ubicaciÃ³n    | Market segmentation   |

## âœ… **Beneficios de esta TransformaciÃ³n**

### **ğŸ¯ Para el MLOps Engineer:**

1. **ğŸ”„ Reproducibilidad**: Mismo resultado siempre
2. **âš¡ AutomatizaciÃ³n**: Integrable en pipelines CI/CD
3. **ğŸ›¡ï¸ Robustez**: Manejo de errores y edge cases
4. **ğŸ“ˆ Escalabilidad**: Procesa cualquier volumen
5. **ğŸ”§ Mantenibilidad**: CÃ³digo modular y testeable
6. **ğŸ¯ Consistencia**: Entrenamiento = ProducciÃ³n

### **ğŸ¯ Para el Modelo ML:**

1. **ğŸ“Š MÃ¡s informaciÃ³n**: 25 features vs 7 originales
2. **ğŸ¯ Mejor predicciÃ³n**: Features especÃ­ficas del dominio
3. **ğŸ”„ Transformaciones aprendidas**: No data leakage
4. **ğŸ“ˆ GeneralizaciÃ³n**: Manejo robusto de datos nuevos

## ğŸ§ª **Testing del Pipeline**

AutomatizaciÃ³n del Script en GitHub Actions

Para llevar todo a un entorno real de integraciÃ³n continua, puedes configurar tu flujo de procesamiento de datos como un **workflow automatizado** con GitHub Actions:

### ğŸ§¾ `.github/workflows/mlops-pipeline.yml`

```yaml
name: MLOps Pipeline

on:
  workflow_dispatch:
    inputs:
      run_all:
        description: "Run all jobs"
        required: false
        default: "true"

jobs:
  data-processing:
    name: Data Processing
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.11.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Process data
        run: |
          python src/data/run_processing.py --input data/raw/house_data.csv --output data/processed/cleaned_house_data.csv

      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed/cleaned_house_data.csv

  feature-engineering:
    name: Feature Engineering
    needs: data-processing
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Download processed data
        uses: actions/download-artifact@v4
        with:
          name: processed-data
          path: data/processed/

      - name: Engineer features
        run: |
          python src/features/engineer.py --input data/processed/cleaned_house_data.csv --output data/processed/featured_house_data.csv --preprocessor models/trained/preprocessor.pkl

      - name: Upload featured data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed/featured_house_data.csv

      - name: Upload preprocessor
        uses: actions/upload-artifact@v4
        with:
          name: preprocessor
          path: models/trained/preprocessor.pkl
```

> ğŸš€ Esto permite que el procesamiento de datos se ejecute automÃ¡ticamente cada vez que lo dispares manualmente o se cree una nueva versiÃ³n.

---
