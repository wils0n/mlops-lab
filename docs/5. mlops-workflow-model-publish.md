# MLOps Workflow: Model Training y Docker Publishing

Este documento describe la configuración del workflow de GitHub Actions para entrenar modelos y publicar imágenes Docker en Docker Hub.

## Requisitos Previos

- Data processing completado (job `data-processing`)
- Feature engineering completado (job `feature-engineering`)
- Ejecución 03_experimentation.ipynb (esto genera el archivo `model_config.yaml`)
- Script para entrenamiento del modelo (`src/models/train_model.py`)
- Dockerfile configurado en la raíz del proyecto
- Cuenta en Docker Hub
- Repositorio configurado con variables y secretos (Se configurará enn los próximos pasos)
- API con endpoint `/health` implementado

## Configuración de Credenciales Docker Hub

### 1. Crear Token de Acceso en Docker Hub

1. Inicia sesión en [Docker Hub](https://hub.docker.com)
2. Ve a **Account Settings** > **Security**
3. Clic en **New Access Token**
4. Asigna un nombre descriptivo (ej: "github-actions-mlops")
5. Selecciona permisos: **Read, Write, Delete**
6. Copia el token generado (solo se muestra una vez)

### 2. Configurar Variables en GitHub

En tu repositorio de GitHub:

1. Ve a **Settings** > **Secrets and variables** > **Actions**
2. En la pestaña **Variables**, agrega:
   - `DOCKERHUB_USERNAME`: Tu nombre de usuario de Docker Hub

### 3. Configurar Secrets en GitHub

En la misma sección, pestaña **Secrets**, agrega:

- `DOCKERHUB_TOKEN`: El token de acceso generado en Docker Hub \*

\* Account settings > Personal access token

## Jobs del Workflow

### Job: model-training

Entrena el modelo usando MLflow para tracking de experimentos y genera el modelo final.

**Dependencias**: `feature-engineering` (requiere datos con features y preprocessor)

**Artefactos de entrada**:

- `featured-data`: Datos con features engineered (`featured_house_data.csv`)

**Artefactos de salida**:

- `trained-model`: Modelo entrenado y archivos relacionados (carpeta `models/`)

**Flujo de datos**:

```
featured-data (csv) → MLflow tracking → trained-model (pkl/joblib)
```

**Pasos principales**:

1. **Checkout**: Descarga el código del repositorio
2. **Setup Python**: Configura Python 3.11.9
3. **Install dependencies**: Instala dependencias desde requirements.txt
4. **Download featured data**: Descarga datos con features del job `feature-engineering`
5. **Set up MLflow**: Levanta servidor MLflow en contenedor Docker para tracking
6. **Wait for MLflow**: Espera a que MLflow esté disponible con health check
7. **Train model**: Ejecuta entrenamiento con tracking MLflow y guarda modelo
8. **Upload model**: Sube modelo entrenado como artefacto para siguiente job
9. **Cleanup**: Limpia contenedores MLflow para liberar recursos

```yaml
model-training:
  name: Model Training
  needs: feature-engineering
  runs-on: ubuntu-latest

  steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: "3.11.9"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Download processed data
      uses: actions/download-artifact@v4
      with:
        name: processed-data
        path: data/processed/

    - name: Download featured data
      uses: actions/download-artifact@v4
      with:
        name: featured-data
        path: data/processed/

    - name: Set up MLflow
      run: |
        docker pull ghcr.io/mlflow/mlflow:latest
        docker run -d -p 5000:5000 --name mlflow-server ghcr.io/mlflow/mlflow:latest mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow.db

    - name: Wait for MLflow to start
      run: |
        for i in {1..10}; do
          curl -f http://localhost:5000/health || sleep 5;
        done

    - name: Train model
      run: |
        mkdir -p models
        python src/models/train_model.py --config configs/model_config.yaml --data data/processed/featured_house_data.csv --models-dir models --mlflow-tracking-uri http://localhost:5000

    - name: Upload trained model
      uses: actions/upload-artifact@v4
      with:
        name: trained-model
        path: models/

    - name: Clean up MLflow
      run: |
        docker stop mlflow-server || true
        docker rm mlflow-server || true
```

### Job: build-and-publish

Construye y publica la imagen Docker del modelo en Docker Hub para deployment en producción.

**Dependencias**: `model-training` (requiere modelo entrenado y preprocessor)

**Artefactos de entrada**:

- `trained-model`: Modelo entrenado y archivos relacionados (carpeta `models/`)
- `preprocessor`: Preprocessor entrenado (`preprocessor.pkl`)

**Artefactos de salida**:

- **Docker Image**: Imagen publicada en Docker Hub con tags:
  - `username/house-price-model:commit-hash` (versionado específico)
  - `username/house-price-model:latest` (versión más reciente)

**Flujo de datos**:

```
trained-model + preprocessor + Dockerfile → Docker Build → Docker Test → Docker Push (Docker Hub)
```

**Pasos principales**:

1. **Checkout**: Descarga el código del repositorio
2. **Download trained model**: Descarga modelo entrenado del job `model-training`
3. **Download preprocessor**: Descarga preprocessor del job `feature-engineering`
4. **Setup Docker Buildx**: Configura constructor Docker avanzado para multi-platform
5. **Build and test**: Construye imagen Docker y la prueba localmente
   - Construye imagen con tag basado en commit hash
   - Ejecuta contenedor de prueba en puerto 8000
   - Verifica health endpoint (`/health`)
   - Muestra logs para debugging
6. **Clean up test**: Limpia contenedor de prueba
7. **Login Docker Hub**: Autentica con Docker Hub usando credenciales configuradas
8. **Push image**: Publica imagen con múltiples tags a Docker Hub

```yaml
build-and-publish:
  name: Build and Publish
  needs: model-training
  runs-on: ubuntu-latest

  steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Download trained model
      uses: actions/download-artifact@v4
      with:
        name: trained-model
        path: models/

    - name: Download preprocessor
      uses: actions/download-artifact@v4
      with:
        name: preprocessor
        path: models/trained/

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v1

    - name: Build and test Docker image
      run: |
        COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
        docker build -t docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:$COMMIT_HASH -f Dockerfile .
        docker run -d -p 8000:8000 --name test-api docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:$COMMIT_HASH
        for i in {1..10}; do
          curl -f http://localhost:8000/health && break || sleep 5;
        done
        docker logs test-api

    - name: Clean up Test Container
      run: |
        docker stop test-api || true
        docker rm test-api || true

    - name: Log in to DockerHub Registry
      uses: docker/login-action@v2
      with:
        registry: docker.io
        username: ${{ vars.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}

    - name: Push Docker image to DockerHub
      run: |
        COMMIT_HASH=$(echo ${{ github.sha }} | cut -c1-7)
        docker tag docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:$COMMIT_HASH docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
        docker push docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:$COMMIT_HASH
        docker push docker.io/${{ vars.DOCKERHUB_USERNAME }}/house-price-model:latest
```

## Características Importantes

### Flujo Completo de Artefactos

El pipeline completo maneja artefactos de la siguiente manera:

1. **data-processing** → genera `processed-data` (cleaned_house_data.csv)
2. **feature-engineering** → consume `processed-data`, genera `featured-data` + `preprocessor`
3. **model-training** → consume `processed-data` + `featured-data`, genera `trained-model`
4. **build-and-publish** → consume `trained-model` + `preprocessor`, genera Docker image

### MLflow Integration

- Servidor MLflow temporal para tracking de experimentos
- Backend SQLite para almacenamiento local durante CI/CD
- Health check para asegurar disponibilidad antes del entrenamiento
- Limpieza automática de contenedores para evitar conflictos

### Docker Image Testing

- **Pre-deployment testing**: La imagen se prueba antes de ser publicada
- **Health endpoint verification**: Verificación automática del endpoint `/health`
- **Container logs**: Captura de logs para debugging en caso de fallos
- **Port mapping**: Prueba en puerto 8000 (puerto estándar del API)

### Docker Image Tagging

- **Tag con commit hash**: Para versionado específico y trazabilidad
- **Tag latest**: Para la versión más reciente en producción
- **Formato**: `username/house-price-model:commit-hash` y `username/house-price-model:latest`
- **Doble push**: Asegura que tanto la versión específica como latest estén disponibles

### Gestión de Artefactos

**Jobs y sus artefactos**:

| Job                   | Artefactos de entrada           | Artefactos de salida            |
| --------------------- | ------------------------------- | ------------------------------- |
| `data-processing`     | Raw data (repo)                 | `processed-data`                |
| `feature-engineering` | `processed-data`                | `featured-data`, `preprocessor` |
| `model-training`      | `featured-data`                 | `trained-model`                 |
| `build-and-publish`   | `trained-model`, `preprocessor` | Docker image (Docker Hub)       |

**Persistencia de artefactos**:

- Artefactos de GitHub Actions se conservan entre jobs del mismo workflow
- Docker images se publican en Docker Hub para acceso externo
- MLflow tracking es temporal (solo durante el job de entrenamiento)

## Troubleshooting

### Error de Autenticación Docker Hub

- Verificar que `DOCKERHUB_USERNAME` (variable) y `DOCKERHUB_TOKEN` (secret) estén configurados
- Confirmar que el token tiene permisos de escritura en Docker Hub
- Verificar que el username sea exactamente el de Docker Hub (case-sensitive)

### MLflow No Responde

- El workflow incluye retry logic con timeout de 10 intentos
- Verificar logs del contenedor MLflow: `docker logs mlflow-server`
- Puerto 5000 debe estar disponible en el runner
- Imagen de MLflow debe estar disponible: `ghcr.io/mlflow/mlflow:latest`

### Imagen Docker Falla Test

- **Health endpoint no responde**: Verificar que `/health` endpoint esté implementado en la API
- **Puerto no disponible**: Confirmar que la aplicación escuche en puerto 8000
- **Dockerfile mal configurado**: Revisar que el Dockerfile copie todos los archivos necesarios
- **Dependencias faltantes**: Verificar que requirements.txt incluya todas las dependencias
- **Modelos no encontrados**: Confirmar que los paths de modelos en el código coincidan con la estructura de artefactos

### Artefactos No Encontrados

- **featured-data faltante**: Verificar que el job `feature-engineering` haya completado exitosamente
- **trained-model no disponible**: Confirmar que `model-training` termine sin errores
- **preprocessor missing**: Verificar que `feature-engineering` genere y suba el preprocessor
- **Path mismatches**: Confirmar que los paths de download coincidan con los de upload

### Error en Train Model

- **Config file not found**: Verificar que `configs/model_config.yaml` exista en el repo
- **Data path incorrect**: Confirmar que `featured_house_data.csv` esté en la ubicación correcta
- **MLflow connection failed**: Verificar que MLflow server esté corriendo en `http://localhost:5000`

## Validación del Pipeline

### Antes de ejecutar

1. **Verificar archivos requeridos**:

   ```bash
   ls src/models/train_model.py
   ls configs/model_config.yaml
   ls Dockerfile
   ls requirements.txt
   ```

2. **Validar estructura de API**:

   - Endpoint `/health` implementado
   - Puerto 8000 configurado
   - Manejo de modelos en el código

3. **Confirmar configuración GitHub**:
   - Variable `DOCKERHUB_USERNAME` configurada
   - Secret `DOCKERHUB_TOKEN` configurado
   - Token con permisos Read/Write/Delete

## Siguiente Paso

Una vez configurado este workflow:

1. **Modelo disponible**: El modelo entrenado estará disponible como imagen Docker en Docker Hub
2. **Versionado**: Cada commit generará una versión específica de la imagen
3. **Testing automático**: La imagen será probada antes de ser publicada
4. **Ready for deployment**: La imagen estará lista para deployment en cualquier plataforma que soporte Docker

## 🎯 Próximos Pasos

- **Prueba de la imagen**: Usar la imagen Docker para deployment a un entorno local, AWS, GCP, Azure, etc.
- **Monitoring**: Implementar monitoring de la aplicación con Prometheus y Grafana
