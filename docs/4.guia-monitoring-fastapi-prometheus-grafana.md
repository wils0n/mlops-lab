# 🛠️ Monitoreo de FastAPI con Prometheus y Grafana

## 🎯 Objetivo

Instrumentar una API en **FastAPI** para recolectar métricas con **Prometheus** y visualizarlas en **Grafana**.

---

## 🧩 Estructura del entorno

```
mlops-lab/
├── docker-compose.yml
├── prometheus/
│   └── prometheus.yml
├── app/
│   └── main.py
│   └── requirements.txt
```

---

## ✅ 1. API FastAPI con Prometheus Instrumentation

### 📄 `src/api/main.py`

```python
from fastapi import FastAPI
from prometheus_fastapi_instrumentator import Instrumentator # agregar este imort

# Initialize FastAPI app with metadata
app = FastAPI(
    title="House Price Prediction API",
    description=(
        "An API for predicting house prices based on various features. "
        "This application is part of the MLOps Bootcamp by School of Devops. "
        "Authored by Gourav Shah."
    ),
    version="1.0.0",
    contact={
        "name": "School of Devops",
        "url": "https://schoolofdevops.com",
        "email": "learn@schoolofdevops.com",
    },
    license_info={
        "name": "Apache 2.0",
        "url": "https://www.apache.org/licenses/LICENSE-2.0.html",
    },
)

Instrumentator().instrument(app).expose(app). # agregar esta configuracion

# dejar codigo existente que sigue como app.add_middleware(...)

```

### 📄 `src/api/requirements.txt`

```
prometheus-fastapi-instrumentator
```

---

## 🐳 2. Dockerización de los servicios

### 📄 `docker-compose.yml`

```yaml
version: "3.8"

services:
  api:
    image: pytuxi/house-price-model:v1.0.3
    ports:
      - "8000:80"

  streamlit:
    image: pytuxi/house-price-streamlit:v1.0.1
    ports:
      - "8501:8501"
    depends_on:
      - api

  prometheus:
    image: prom/prometheus:v2.52.0
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana:10.2.2
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
```

---

## 📊 3. Configuración de Prometheus

### 📄 `monitoring/prometheus/prometheus.yml`

```yaml
global:
  scrape_interval: 15s

scrape_configs:
  - job_name: "fastapi"
    static_configs:
      - targets: ["api:80"]
```

---

## 🚀 4. Levantar los servicios

```bash
docker-compose -f deployment/docker-compose/docker-compose.yaml up -d
```

---

## 🔍 5. Validaciones

### 🔸 Prometheus

Navega a:

```
http://localhost:9090/targets
```

Consulta métricas como:

```
http_requests_total
process_cpu_seconds_total
```

### 🔸 Grafana

1. Ir a: `http://localhost:3000`
2. Usuario/contraseña: `admin / admin`
3. Configurar datasource:
   - **Type**: Prometheus
   - **URL**: `http://prometheus:9090`
4. Guardar y testear

---

## 📈 6. Crear un dashboard en Grafana

1. `+ Create` → Dashboard → Add Panel
2. En “Query”:
   ```
   http_server_requests_total{job="fastapi"}
   ```
3. Visualiza en formato **Time Series**

---

## 🧪 7. Simular tráfico

```bash
curl http://localhost:8000/
curl http://localhost:8000/predict
```

---

## 🧼 8. Para detener

```bash
docker-compose down
```

---

## 📊 9. Importar y personalizar el dashboard de Grafana (ID: 15834)

Grafana proporciona un dashboard listo para usar con FastAPI:  
👉 [https://grafana.com/grafana/dashboards/15834-fastapi](https://grafana.com/grafana/dashboards/15834-fastapi)

### 📥 Pasos para importar:

1. Ir a Grafana `http://localhost:3000`
2. Menú lateral → **+ Create → Import**
3. En "Import via grafana.com", ingresa el ID: `15834`
4. Click en **Load**
5. Selecciona el datasource Prometheus configurado
6. Click en **Import**

---

## 📈 10. Indicadores clave del dashboard

Aquí algunos paneles útiles incluidos (y cómo actualizarlos si fuera necesario):

### 🔸 Request per second (total)

```promql
rate(http_server_requests_total{job="fastapi"}[1m])
```

> Si no ves datos, aumenta el rango a `[5m]`.

### 🔸 Request duration (latencia)

```promql
histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="fastapi"}[5m]))
```

### 🔸 CPU Usage (seconds per second)

```promql
rate(process_cpu_seconds_total{job="fastapi"}[1m])
```

Multiplica por 100 si quieres verlo en `%` para 1 core.

### 🔸 Porcentaje de respuestas exitosas (2xx)

```promql
sum(rate(http_server_requests_total{job="fastapi", status=~"2.."}[1m]))
/
sum(rate(http_server_requests_total{job="fastapi"}[1m]))
```

### 🔸 Códigos 4xx y 5xx

```promql
sum(rate(http_server_requests_total{job="fastapi", status=~"4.."}[1m]))
```

```promql
sum(rate(http_server_requests_total{job="fastapi", status=~"5.."}[1m]))
```

---

## 🧪 11. Sugerencia de tráfico para alimentar las métricas

Usa el script `generate_traffic.py` para enviar solicitudes `GET /` y `POST /predict` automáticamente y observar cómo se llenan los paneles en tiempo real.
